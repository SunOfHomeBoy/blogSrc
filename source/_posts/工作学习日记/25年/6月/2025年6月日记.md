---
title: 2025年6月日记
date: 2025年6月3日 13:18:25
update: 
tags: 日记
categories: Diary
---

# 2025年6月3日 13:18:52 周二
  节后第一天

  + [python环境搭建](./python环境搭建.md)


  + [三步恢复肝脏](./三步恢复肝脏.md)
    1. 戒糖(饮料、水果、各种含糖零食)
    2. 轻断食(晚上不吃饭！不管自己多么痛苦)
    3. 适量运动(尽量骑自行车，周末爬山)

# 2025年6月6日 周五
  + Q: 我是一个程序员，从开发的角度来说。目前都有哪些最新的AI技术？

  + A: 从开发者的角度来看，目前最新的AI技术主要集中在以下几个领域：
    1. 大语言模型（LLM）
      - GPT系列、LLaMA、PaLM等
      - 支持长上下文理解、多轮对话
      - 代码生成和解释能力
      - 应用：智能助手、代码补全、文档生成
    2. 多模态AI
      - 文本、图像、音频、视频的联合理解
      - CLIP、Stable Diffusion等模型
      - 应用：图像生成、视频理解、跨模态搜索
    3. 生成式AI
      - 文本生成：ChatGPT、Bard
      - 图像生成：DALL-E、Midjourney
      - 视频生成：Runway、Pika
      - 应用：内容创作、设计辅助
    4. 强化学习
      - AlphaGo、AlphaZero等
      - 应用：游戏AI、机器人控制、资源优化
    5. 边缘AI
      - 在设备端运行的轻量级模型
      - TensorFlow Lite、Core ML
      - 应用：移动端AI、物联网设备
    6. AI开发工具
      - LangChain：构建LLM应用
      - Hugging Face：模型库和工具
      - PyTorch 2.0：动态图优化
      - JAX：高性能数值计算
    7. AI安全与伦理
      - 模型解释性
      - 数据隐私保护
      - 对抗性攻击防御
    8. AI基础设施
      - 分布式训练框架
      - 模型压缩与量化
      - 高性能推理引擎
    9. 领域专用AI
      - 生物医药：蛋白质结构预测
      - 金融：风险预测、交易策略
      - 教育：个性化学习
    10. AI与区块链结合
      - 去中心化AI
      - 数据市场
      - 模型验证

    - 对于开发者来说，建议关注：
      1. 掌握主流AI框架（PyTorch、TensorFlow）
      2. 学习Prompt Engineering
      3. 了解模型微调和部署
      4. 关注AI安全与伦理
      5. 探索AI在新领域的应用

    这些技术正在快速发展，为开发者提供了广阔的机会和挑战。

  + 解决 ollama wsl 访问问题
    ```powershell
      $env:OLLAMA_HOST = "http://0.0.0.0:11434"
      ollama serve
    ```

    ```wsl.Ubuntu.sh
    ip route | grep default
      default via 172.27.176.1 dev eth0 proto kernel

    curl http://172.27.176.1:11434/api/tags
    ```

  + 下周工作计划
    + STT & TTS 代理接口开发
    + 解决 浏览器 https 跨域，跨协议 问题
    + 服务的 增加 接口报错日志记录
    + 数字人播报接口业务逻辑开发
    + 数据 和 话术 给到大模型，大模型进行自然语言处理
    + 数字人问题回答 接口业务逻辑开发

# 2025年6月9日 周一
  ## Ubuntu 安装docker
  以下是 ​​Ubuntu 系统更换清华大学镜像源（含 Docker 仓库）的完整步骤​​，结合网络优化和常见问题修复：

  + ​​一、更换 Ubuntu 系统镜像源​​
    +  步骤 1：备份原有源文件​​
      > sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak

    + ​​步骤 2：配置清华源​​
      ```sh
      # 清空旧配置（适用于 Ubuntu 20.04，其他版本替换 focal 为对应代号）
      > sudo sed -i 's@http://.*archive.ubuntu.com@https://mirrors.tuna.tsinghua.edu.cn@g' /etc/apt/sources.list
      > sudo sed -i 's@http://.*security.ubuntu.com@https://mirrors.tuna.tsinghua.edu.cn@g' /etc/apt/sources.list

      # 或手动写入（推荐）
      echo -e "deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse\n\
      deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse\n\
      deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse\n\
      deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse\n\
      deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse\n\
      deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse\n\
      deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse\n\
      deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse" | sudo tee /etc/apt/sources.list
      ```

    + ​​步骤 3：更新软件列表​​
      > sudo apt update && sudo apt upgrade -y

  + 二、配置 Docker 清华镜像源​​
    + ​​步骤 1：备份原有 Docker 源​​
      > sudo mkdir -p /etc/apt/sources.list.d/docker.backup
      > sudo mv /etc/apt/sources.list.d/docker.list* /etc/apt/sources.list.d/docker.backup/
    + ​​步骤 2：添加清华 Docker 仓库​​
      ```sh
      # 导入 GPG 密钥（清华镜像站提供）
      > sudo mkdir -p /usr/share/keyrings
      > sudo curl -fsSL https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
      
      # 写入仓库配置
      echo \
        "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] \
        https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu \
        focal stable" | \
        sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
      ​​步骤 3：更新并安装 Docker​​
      sudo apt update
      sudo apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
      ```

  + ​​三、验证配置​
    + 1. 检查镜像源生效​​
      ```sh
      grep -A 3 "docker" /etc/apt/sources.list.d/docker.list
      预期输出：
      deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu focal stable
      ```
    ​​+ 2. 测试 Docker 安装​​
      > sudo systemctl start docker
      > sudo docker run hello-world  # 输出 "Hello from Docker!" 表示成功

  ## docker 运行 emoti-voice:v2
    > docker run -d -p 6005:6005 emoti-voice:v2

    > http://192.168.0.160:6005/docs
    > http://127.0.0.1:6005/docs // 本地回环网络

  ## 语音播报事件测试

  ## 接口报错log日志测试
    TTS Error
    > 2025-06-09 18:24:18,776 - ERROR - [2025-06-09 18:24:18.775836] TTS Error - Server returned error: Internal server error. Please check the logs for details.

# 2025年6月10日 周二
  我准备在 Ubuntu 服务器上部署 ollama docker镜像。
  但是 Ubuntu上 VPN不稳定，拉取失败。
  所以我准备 在 win11 上的 docker desktop 容器中 拉取 ollama docker 镜像，并在 Ubuntu 服务器上部署。
  请你给出具体方案
  所有系统 都是 x86_64 架构

  首先，请你用中文交流。
  其次，我想知道 如何搜索 ollama 的 docker 镜像。我想在 win11 docker desktop 上的 wsl Ubuntu 20.04 上拉取，然后 部署到我的 Ubuntu 服务器上。
  都是x86_64 架构

  + Ollama Docker 镜像打包
    1. 找到官方镜像
      > docker pull ollama/ollama:latest

    2. 本地运行 ollama/ollama:latest 镜像
      > docker run -d --name ollama_container -p 11434:11434 ollama/ollama:latest

    3. 检查 ollama 服务是否正常运行
      ```sh
      > docker run -d --name ollama_container -p 11434:11434 ollama/ollama:latest
      a09fee1963dfcfae27a470a4e883084e8caf3354ab66ffcd0dc6ff21b5d6f999
      > ollama -h
      ollama: command not found
      > docker ps
      CONTAINER ID   IMAGE                  COMMAND               CREATED          STATUS          PORTS                                             NAMES
      a09fee1963df   ollama/ollama:latest   "/bin/ollama serve"   53 seconds ago   Up 53 seconds   0.0.0.0:11434->11434/tcp, [::]:11434->11434/tcp   ollama_container
      ```
    4. 通过`浏览器` | `命令行`与 Ollama 交互
      + 4.1 访问本地 API 接口
        `http://172.27.176.1:11434/`
        `http://127.0.0.1:11434/api/tags`
      + 4.2 使用命令行操作 Ollama
        ```bash
        > docker exec -it ollama_container sh
        # ollama pull qwen3:32b
        7MB/s
        ```
        **等待 拉取模型文件**
    5. ollama 本地Docker镜像 打包
      - 基础信息
      ```sh
        > docker run -d --name ollama_container -p 11434:11434 ollama/ollama:latest
          a09fee1963dfcfae27a470a4e883084e8caf3354ab66ffcd0dc6ff21b5d6f999

        > docker ps
        CONTAINER ID   IMAGE                  COMMAND               CREATED       STATUS       PORTS                                             NAMES
        a09fee1963df   ollama/ollama:latest   "/bin/ollama serve"   2 hours ago   Up 2 hours   0.0.0.0:11434->11434/tcp, [::]:11434->11434/tcp   ollama_container

        > docker exec -it ollama_container sh
        # ollama list
        NAME         ID              SIZE     MODIFIED
        qwen3:32b    030ee887880f    20 GB    21 minutes ago
      ```

      1. 将容器提交为新镜像
        > docker commit ollama_container ollama_qwen3_32b_container

      2. 导出镜像 为 tar 文件：
        如果您需要将这个镜像传输到其他服务器或环境，您可以导出为 tar 文件并在目标环境中加载：

        > docker save -o ollama_qwen3_32b_container.tar ollama_qwen3_32b_container

    6. 目标服务器 copy镜像：
      
    7. 目标服务器 加载镜像：
      > docker load -i ollama_qwen3_32b_container.tar

    8. 服务器本地运行 ollama_qwen3_32b_container 镜像
      > docker run -d --name ollama_container -p 11434:11434 ollama_qwen3_32b_container

  + 数字人Agent 打包部署测试

  + 安装 Nginx

  ## 问题
    本地无法运行 32b 模型，提示内存不足。

    qwen3:32b模型 智能程度 比 qwen2.5:14b 更高

    我已经部署了 ollama docker 镜像。我现在需要 开启 docker GPU 支持

    1. 开启 docker GPU 支持(已开启 GPU支持)
      ollama 是否使用 GPU资源？
      目前通过资源监控，发现 CPU占用率 超高，但是 GPU占用率 0%。

    2. STT&TTS 接口无法访问，如何排查问题？
      docker exec -it elegant_sanderson bash
      * docker 包里 没有安装 调试工具，服务器安装速度、重新配置  需要时间

    3. 替换 qwen2.5:14b 模型

    4. LangChain 不支持 思考大模型，如何解决？

    5. LangChain 会 多轮思考，所以 等待时间就变更长了。
      如果 绕开LangChain 直接调用 Ollama API 响应速度还可以。

  ## 优化
    1. 流式响应
    2. 音频队列
    3. 音频ws接口
  
  ## 服务器 运行命令
    **STT&TTS**
    > docker run -d --name STT_TTS_container --restart unless-stopped -p 6005:6005 emoti-voice:v2
    **Ollama**
    > docker run -d --name ollama_container_GPU --restart unless-stopped -p 11434:11434 ollama_qwen3_32b_container
    **Ollama GPU 模式**
    > docker run -d --name ollama_container_GPU --restart unless-stopped -p 11434:11434 --gpus all -e NVIDIA_VISIBLE_DEVICES=0 -e OLLAMA_DEVICE=cuda ollama_qwen3_32b_container
      // -v /opt/ai/ollama:/root/.ollama \  # 挂载模型存储目录 * 可选配置 不需要
    ```sh
      # 检查 STT&TTS 容器
      docker ps -a | grep emoti-voice

      docker exec -it STT_TTS_container bash
    ```
    **数字人Agent**

  ## 钉钉工作日志
    + 调试 服务器
      + 安装并调试 Todesk、SSH 链接工具
      + 配置远程 唤醒服务器功能
    + 安装 VPN
    + 安装 docker
      + 部署 emoti-voice:v2 STT & TTS Docker包
      + 测试功能
    + 安装 ollama
      + VPN 问题，导致 下载总是出错
    + 编写 STT & TTS 服务，请求代理接口，并增加 log日志记录
      + 根据 服务返回错误日志，增加 拦截规则

    + 配置 Ubuntu 镜像源
      > cat /etc/apt/sources.list
    + 配置 docker 镜像源


# 2025年6月11日 周三
  ## [增加同型号 P40GPU](./多GPU支持.md)

  ## P40运行32b大模型文章分析
  1. https://blog.csdn.net/hai4321/article/details/146106017
  2. https://community.modelscope.cn/6740480fcd8b2677c3e4cc31.html

  ## [大模型同步](./大模型同步.md)
  
  ## 重新打包 STT&TTS docker镜像
    1. 创建镜像
      docker commit naughty_thompson stt_tts_serve:v1
    2. 验证镜像
      docker images
    3. 导出镜像
      docker save -o stt_tts_serve.tar stt_tts_serve:v1

    + 加载镜像
      docker load -i stt_tts_serve.tar
      docker run -d --name STT_TTS_container --restart unless-stopped -p 6005:6005 stt_tts_serve:v1

  ## 今日进展
  1. 解决大模型 14b 模型同步
  2. 32b 速度慢，有 LangChain 拖累，需要多次 调用 API
  3. 重新打包 STT&TTS docker镜像
    通过分析日志，原 docker 需要 联网 下载其他包
    在本地加载，downloading 完后 重新打包，即可解决

# 2025年6月12日 周四
  + ws 交互逻辑开发
    - 根据 话术，生成对应文字解析
  + 

# 2025年6月13日 周五
  + 导出 Agent 镜像
    1. 导出conda 环境
    > conda env export > environment.yml
    2. pip 导出
    > pip freeze > requirements.txt

  + 构建镜像
    > docker build -f ./DigitalMan.dockerfile -t digitalman .

  + 运行调试容器
    > docker run -d --name digitalman_container -p 9880:9880 digitalman

  + 查看日志
    > docker logs digitalman_container

  + 导出 tar包
    > docker save -o digitalman.tar digitalman_container:v1
    > docker save -o digitalman.tar digitalman

  + 服务器 加载 tar包
    > docker load -i digitalman.tar

  + 服务器运行容器
    > docker run -d --name digitalman_container --restart unless-stopped -p 9880:9880 digitalman

  ## 解决 服务器 网络代理问题
    ```sh
      # 停止Clash后台服务
      sudo systemctl stop clash
      # 禁用开机自启
      sudo systemctl disable clash

      # 临时清除当前会话代理(切换其他 命令行 或 浏览器 不生效)
      unset http_proxy https_proxy all_proxy HTTP_PROXY HTTPS_PROXY ALL_PROXY

      # 永久清除（检查所有配置文件）
      grep -r "proxy" ~/.bashrc ~/.profile ~/.bash_profile /etc/environment 2>/dev/null
      # 找到后注释或删除相关行
      # 永久清除（检查以下文件）
      grep -r "proxy" ~/.bashrc ~/.profile ~/.b
    ```

  ## 配置docker镜像 apt-get镜像源

  ## 重新生成 ssl证书
    ```bash
      > os@os-S2600WFT:/etc/nginx/ssl$ pwd
      /etc/nginx/ssl
      > os@os-S2600WFT:/etc/nginx/ssl$ nano req.conf
      [req]
      distinguished_name = req_distinguished_name
      x509_extensions = v3_req
      prompt = no

      [req_distinguished_name]
      C = CN
      ST = Beijing
      L = Beijing
      O = ZSGX
      OU = DevTeam
      CN = 192.168.0.26

      [v3_req]
      keyUsage = keyEncipherment, dataEncipherment
      extendedKeyUsage = serverAuth
      subjectAltName = @alt_names

      [alt_names]
      IP.1 = 192.168.0.26
      DNS.1 = localhost 
    ```
    重要：
      CN = 192.168.0.26：这里的CN（Common Name）最好也写成你的IP。
      IP.1 = 192.168.0.26：这是最关键的一行，它在SAN字段中指定了这个证书对该IP地址有效。

    + 生成新私钥
    ```sh
    # 生成新私钥(key.pem)和新的证书(cert.pem)
    openssl req -x509 -nodes -days 3650 -newkey rsa:2048 -keyout key.pem -out cert.pem -config req.conf
    ```
  + 重启 Nginx
    > sudo systemctl restart nginx
  + 测试 Nginx 配置是否正确
    > sudo nginx -t

  + Nginx 运行状态
    > sudo systemctl status nginx

  * 重新生成的证书有问题，恢复旧证书

  ## 分析大模型回复接口返回null问题
    + 前端优化，增加提示词
      `const msg = res.result || '对不起，我没听清楚，请再说一遍'`
    + 提取运行日志
      ```sh
        # 查找容器ID
        CONTAINER_ID=$(docker ps -aq --filter name=<容器名>)
        > docker ps -a

        # 清空日志文件(无须重启)
        sudo truncate -s 0 /var/lib/docker/containers/$CONTAINER_ID/$CONTAINER_ID-json.log

        # 日志文件路径(删除log文件需重启容器)
        sudo rm /var/lib/docker/containers/$CONTAINER_ID/$CONTAINER_ID-json.log
      ```
  + python3 一行命令 http服务
    python -m http.server 8000 // --bind 127.0.0.1

# 2025年6月14日 周六
  + 服务器 docker 镜像包
    ```sh
      os@os-S2600WFT:~/download_pub$ docker images
      REPOSITORY                   TAG                       IMAGE ID       CREATED         SIZE
      digitalman                   latest                    7d5a2b0bdded   25 hours ago    1.75GB /** 第二版 没有回答问题 */
      <none>                       <none>                    9b3a8568be54   28 hours ago    1.28GB /** 估计是第一版 */
      stt_tts_serve                v1                        552b3992f9fa   2 days ago      13.4GB
      ollama_qwen3_32b_container   latest                    e7c50030d6a6   4 days ago      23.7GB
      emoti-voice                  v2                        5417b338b259   9 days ago      13.3GB
      nvidia/cuda                  11.8.0-base-ubuntu22.04   1e75b7decac0   19 months ago   239MB
    ```
  
  + 保存之前V2 镜像
    ```bash
    # 提交容器为镜像
    docker commit digitalman_container digitalman_v2

    # 导出镜像为 tar
    docker save -o digitalman_v2.tar digitalman_v2

    # 其他服务器 加载验证
    docker load -i digitalman_v2.tar
    docker run -d --name digitalman_container --restart unless-stopped -p 9880:9880 digitalman_v2
    ```

  + 部署 易魔声 docker 服务到服务器
    ```bash
      docker pull syq163/emoti-voice:latest

      docker load -i syq163_emoti_voice.tar

      docker run -dp 0.0.0.0:8501:8501 -p 0.0.0.0:8000:8000 syq163_emoti_voice
    ```

# 2025年6月16日 周一
  + 易魔声 容器信息
    ```bash
      os@os-S2600WFT:~/SSh_Docker_DEV/devcontainer$ docker ps
      CONTAINER ID   IMAGE                        COMMAND                   CREATED        STATUS          PORTS                                                   NAMES
      6f75266c3ebf   syq163_emoti_voice           "/bin/sh -c 'streaml…"   40 hours ago   Up 16 minutes   0.0.0.0:8000->8000/tcp, 0.0.0.0:8501->8501/tcp          recursing_diffie
      4ad9a0b3b9e8   digitalman                   "python ./main.py"        42 hours ago   Up 20 minutes   0.0.0.0:9880->9880/tcp, [::]:9880->9880/tcp             digitalman_container
      fbbe6318a1e3   stt_tts_serve:v1             "python testV2.py"        4 days ago     Up 20 minutes   0.0.0.0:6005->6005/tcp, [::]:6005->6005/tcp, 8000/tcp   STT_TTS_container
      dcf9a775ca0e   ollama_qwen3_32b_container   "/bin/ollama serve"       5 days ago     Up 20 minutes   0.0.0.0:11434->11434/tcp, [::]:11434->11434/tcp         ollama_container_GPU
    ```

    ```sh
      # 使用docker inspect命令获取容器的完整配置信息，包括启动命令：
      > docker inspect --format='{{json .Config.Cmd}}' 6f75266c3ebf
      ["/bin/sh","-c","streamlit run demo_page.py --server.port 8501 & uvicorn openaiapi:app --reload --host 0.0.0.0 --port 8000"]
    ```
    从获取的信息来看，容器启动时执行了两个服务：

    Streamlit服务运行demo_page.py在8501端口

    Uvicorn服务运行openaiapi:app在8000端口

  + 易魔声 声音ID list
    ```sh
      os@os-S2600WFT:~/SSh_Docker_DEV/devcontainer$ docker exec recursing_diffie find /EmotiVoice -name "config.py"
      /EmotiVoice/config/joint/config.py
    ```

  + TTS 音频正则
    1. 获取容器命令
      ```sh
      > docker inspect --format='{{json .Config.Cmd}}' fbbe6318a1e3
      ```

  + 服务器 扩展安全维护(ESM)
    ```sh
      Welcome to Ubuntu 20.04.6 LTS (GNU/Linux 5.15.0-139-generic x86_64)

      * Documentation:  https://help.ubuntu.com
      * Management:     https://landscape.canonical.com
      * Support:        https://ubuntu.com/pro

      扩展安全维护（ESM）Infrastructure 未启用。

      4 更新可以立即应用。
      这些更新中有 4 个是标准安全更新。
      要查看这些附加更新，请运行：apt list --upgradable

      8 个额外的安全更新可以通过 ESM Infra 来获取安装。
      可通过以下途径了解如何启用 ESM Infra：for Ubuntu 20.04 at
      https://ubuntu.com/20-04

      New release '22.04.5 LTS' available.
      Run 'do-release-upgrade' to upgrade to it.

      Your Hardware Enablement Stack (HWE) is supported until April 2025.
      Last login: Mon Jun 16 09:48:44 2025 from 192.168.0.43
      Last login: Mon Jun 16 13:45:57 2025 from 192.168.0.43
    ```

  + TTS 进入报错崩溃 docker 容器的方法
    ```sh
      # 1. 停止当前容器
      docker stop STT_TTS_container

      # 2. 修改 docker-compose.yml，添加或修改命令以防止容器立即执行 testV2.py
      # 在 docker-compose.yml 中将 command 改为:
      command: tail -f /dev/null   # 这会让容器保持运行而不是直接执行 Python 脚本

      # 1. 启动容器
      docker-compose up -d

      # 2. 进入容器
      docker exec -it STT_TTS_container /bin/bash

      # 3. 在容器内安装 NLTK 资源
      python3 -c "import nltk; nltk.download('averaged_perceptron_tagger_eng')"

      # 4. 修复 testV2.py 的缩进问题
      vim /path/to/testV2.py

      # 用不同的启动命令覆盖容器的默认命令
      docker run -it --name STT_TTS_container_new image_name /bin/bash
    ```

    - 重新运行 STT_TTS_container 服务
    ```bash
      docker run -d --name STT_TTS_container_v2 --restart unless-stopped -p 6005:6005 stt_tts_serve:v1
    ```

    - 从容器中复制文件到主机
    ```bash
      # 从容器复制文件到主机
      docker cp STT_TTS_container:/app/testV2.py ./testV2.py
      # copy 新v2 文件到主机
      docker cp STT_TTS_container_v2:/app/testV2.py ./testV2_new.py

      # 修改文件后，再复制回容器
      docker cp ./testV2.py STT_TTS_container:/app/testV2.py
    ```

  + 文章阅读 [为什么只谈彩礼不谈嫁妆？](https://mp.weixin.qq.com/s/CD1iu5Ly9qigkJdb5NTfgw)
    回复：
      搞不懂，就不要搞了呗。你不结婚 人类也不会因为你灭亡。
      目前的现状，不是只靠几个人 在网上说几句话就能解决的了的。
      命运车轮 滚滚向前，普通人连只蚂蚁都算不上，就别想着 螳臂当车了。。。

